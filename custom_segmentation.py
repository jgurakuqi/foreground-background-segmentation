import numpy as np
import cv2 as cv

from ipywidgets import interact, fixed


def plot_canny(frame: np.ndarray, low_val: int, max_val: int) -> None:
    """Helper function devised to plot interactive application of canny.

    Args:
        frame (np.ndarray): image from which to extract edges.
        low_val (int): bottom value for Canny.
        max_val (int): top value for Canny.
    """
    from matplotlib import pyplot as plt

    plt.figure(figsize=(10, 10))
    plt.subplot(1, 1, 1)
    edges = cv.Canny(frame, low_val, max_val)
    plt.imshow(edges)
    plt.title("EDGES")


def test_canny_values(frame: np.ndarray) -> None:
    """This function was devised to test how different parameters of canny
    afflict an image.

    Args:
        frame (np.ndarray): Input image used for the tests.
    """
    denoised_frame = cv.fastNlMeansDenoising(frame, None, 10, 7, 21)
    gray_frame = cv.cvtColor(denoised_frame, cv.COLOR_BGR2GRAY)

    interact(
        plot_canny,
        frame=fixed(gray_frame),
        low_val=(1, 60, 1),
        max_val=(1, 60, 1),
    )


def hsv_and_edge_segmentation(frame: np.ndarray) -> np.ndarray:
    """Perform an image segmentation on the input frame to separate the
    object+pedestal+table from the upper background.
    Such segmentation is performed using the H and S channels from the hsv
    colour space, and also using the edges extracted from the original frame.
    (additional morphological and numpy operations are performed to remove
    noise derived from the operations themselves).
    H and S are chosen because they allows to extract easily the object+pedestal
    and the table+rotating surface respectively, whereas any further operation
    allows to perform and improve such extractions.

    In order to find the most suitable values for each step, I used an approach
    similar to the one shown in the "test_canny_values" function.

    Args:
        frame (np.ndarray): Original frame.

    Returns:
        np.ndarray: Transformed frame.
    """
    # Convert to hsv
    hsv_frame = cv.cvtColor(frame, cv.COLOR_RGB2HSV)

    # Extract frame width
    frame_width = hsv_frame.shape[1]

    # Denoise the frame for edge detection.
    denoised_frame = cv.GaussianBlur(frame, (7, 7), 0)
    # cv.fastNlMeansDenoising(frame, None, 10, 7, 21) BETTER RESULTS, BUT 20X TIMES SLOWER!

    # Extract hue and saturation channels: hue for easier object/pedestal extraction, saturation
    # for easier table extraction.
    hue, sat = hsv_frame[:, :, 0], hsv_frame[:, :, 1]

    # Increase the visibility of the table by increasing the saturation around of it.
    # Setting values higher than 190 tend to isolate better the table for thesholding.
    sat[sat > 190] = 200

    # Threshold the saturation channel to obtain a homogenous shot of the table.
    # No otsu because manual thresholding allows for better control over the
    # separation between table and the rest.
    _, thresh = cv.threshold(sat, 155, 255, cv.THRESH_BINARY_INV)

    # Make black such thresholded saturation until the table, to remove artifacts
    # generated by the saturation augmentation without need for excessive morphologies.
    thresh[:, 0 : int(frame_width * 0.5785) :] = 0

    # Closes holes left from the thresholding.
    morph_closed_thresh = cv.morphologyEx(
        thresh, cv.MORPH_CLOSE, np.ones((5, 5)), iterations=2
    )

    # Perform an open to remove potential noise left by the combination
    # of the saturation augmentation and thesholding.
    morph_opened_thresh = cv.morphologyEx(
        morph_closed_thresh, cv.MORPH_OPEN, np.ones((5, 5)), iterations=3
    )

    # Extract edges from the denoised frame.
    frame_edges = cv.Canny(denoised_frame, 60, 60)

    # Dilate such edges to obtain thicker borders.
    frame_edges = cv.dilate(frame_edges, kernel=np.ones((3, 3)), iterations=2)

    # Add the dilated edges to the hue, because the hue usually
    # discards part of the Toucan mouth, while original's image edges do not.
    frame_edges = cv.add(frame_edges, hue)

    # Add the hue+edges to the thresholded (dil+morph) saturation,
    # obtaining the table+object/pedestal.
    hue_sat = cv.add(morph_opened_thresh, frame_edges)

    # Remove low intensities derived from the toucan/hue background.
    hue_sat[hue_sat < 50] = 0

    # Prepare the segmentation, setting every intensity higher than 0
    # to 255 (even under the table).
    hue_sat[hue_sat > 0] = 255

    # Remove fabric corners which can appear on same videos
    # due to a higher visibility in the original frame.
    hue_sat[:, 0 : int(frame_width * 0.2) :] = 0

    # Fill the left part of the image with an intensity of 5, to discriminate
    # it from the zero values under the table (i.e., on the right).
    cv.floodFill(
        hue_sat,
        None,
        seedPoint=(1, 1),
        newVal=(5, 0, 0),
        loDiff=(5, 5, 5, 5),
        upDiff=(5, 5, 5, 5),
    )

    # Set the background to black and the table+pedestal to yellow.
    hue_sat[hue_sat != 5] = 255
    hue_sat[hue_sat == 5] = 0

    # Use the intensity frame to replicate such values over the
    # coloured frame, obtaining the final result in black and white.
    frame[hue_sat > 0] = [255, 255, 255]
    frame[hue_sat == 0] = [0, 0, 0]

    return frame
